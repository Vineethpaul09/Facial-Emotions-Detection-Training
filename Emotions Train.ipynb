{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "id": "xFYRhY5cAT2E",
    "outputId": "3edc5317-b710-4d45-8e52-d14ae6024b02",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from project_libraries import *\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH_EpOQHVr1C"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "The data consists of 48x48 pixel grayscale images of faces. \n",
    "\n",
    "\n",
    "Generally facial expression into one of seven categories that are : 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    " \n",
    "\n",
    "The training set consists of 28,709 examples and the public test set consists of 3,589 examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XPS2LXMkVrG0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emotion</td>\n",
       "      <td>pixels</td>\n",
       "      <td>Usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     usage\n",
       "0  emotion                                             pixels     Usage\n",
       "1        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "2        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "3        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "4        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "5        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
       "6        2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...  Training\n",
       "7        4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...  Training\n",
       "8        3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...  Training\n",
       "9        3  85 84 90 121 101 102 133 153 153 169 177 189 1...  Training"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the data\n",
    "data = './sa.csv'\n",
    "# In the dataset lableling map is 0 as anger, 1=Disgust, 2=Fear.. etc.\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "# the dataset has headers like emotion, pixels and useage\n",
    "headers =['emotion','pixels','usage']\n",
    "df=pd.read_csv(data ,names=headers, na_filter=False)\n",
    "im=df['pixels']\n",
    "# head data \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RdPWfUxV3yl"
   },
   "source": [
    "## Data visualization\n",
    "By this can able understand the dataset, number of data for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jHb2aCfEV0Nr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./sa.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vpRO_NBAV9kU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='emotion', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,4))\n",
    "sns.countplot(x='emotion', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loeSB6qnWHhK"
   },
   "source": [
    "## Analyze the data\n",
    "Lets now analyze how images in the dataset look like how much data is present for each class and how many number of classes are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cSL14-WiWAh8"
   },
   "outputs": [],
   "source": [
    "# Function dataset file is for defining the number of classes\n",
    "def Datasetfile(filname):\n",
    "    # images are 48x48\n",
    "    # N = 35887\n",
    "    Y = [] # y is used name classes\n",
    "    X = [] # x is used for remaining data\n",
    "    first = True\n",
    "    for line in open(filname):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')\n",
    "            Y.append(int(row[0]))\n",
    "            X.append([int(p) for p in row[1].split()])\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9PzOcuC3WKi2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of classes\n",
      "Anger\n",
      "Disgust\n",
      "Fear\n",
      "Happy\n",
      "Sad\n",
      "Suprise\n",
      "Neutral\n",
      "The number of classes are: 7\n"
     ]
    }
   ],
   "source": [
    "X, Y = Datasetfile(data)\n",
    "name_class = set(Y)\n",
    "print(\"The name of classes\")\n",
    "if 0 in name_class:\n",
    "    print(\"Anger\")\n",
    "    if 1 in name_class:\n",
    "        print(\"Disgust\")\n",
    "        if 2 in name_class:\n",
    "            print(\"Fear\")\n",
    "            if 3 in name_class:\n",
    "                print(\"Happy\")\n",
    "                if 4 in name_class:\n",
    "                    print(\"Sad\")\n",
    "                    if 5 in name_class:\n",
    "                        print(\"Suprise\")\n",
    "                        if 6 in name_class:\n",
    "                            print(\"Neutral\")\n",
    "num_class = len(name_class)\n",
    "print(\"The number of classes are:\",num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-8f8BuodWOtr"
   },
   "outputs": [],
   "source": [
    "# keras with tensorflow backend\n",
    "N, D = X.shape\n",
    "X = X.reshape(N, 48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPhRRusmWOe3"
   },
   "source": [
    "splitting the data into train data and test data.\n",
    "Using the 90% data for the training and remaining for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I2vs4qneWXZG"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\n",
    "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDbAx-HXWfZv"
   },
   "source": [
    "## The model:\n",
    "With the help of CNN using 6 convolutional layers including batch normalization, activation, max pooling, dropout layers and flatten layyers. 2 full connected dense layers and finally dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8uJwtvNMWcDZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\vineethpaulpr\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 64)        102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 128)       409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 2,787,015\n",
      "Trainable params: 2,785,863\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def my_model():\n",
    "    \n",
    "    # Sequential is allow the build the model layers by layers\n",
    "    model = Sequential()\n",
    "    # input shape \n",
    "    input_shape = (48,48,1)\n",
    "    # For the output volume size matches the input volume size, by setting the value to the “same”.\n",
    "    padding = 'same'\n",
    "    # activation Relu will help to bring the non linearity in the model\n",
    "    activation = 'relu'\n",
    "    #technique to coordinate the update of multiple layers in the modeland also accelerate learning process\n",
    "    #Normalization = BatchNormalization()\n",
    "    model.add(Conv2D(64, (5, 5), input_shape=input_shape,activation=activation, padding=padding))\n",
    "    model.add(Conv2D(64, (5, 5), activation=activation, padding=padding))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (5, 5),activation=activation, padding=padding))\n",
    "    model.add(Conv2D(128, (5, 5),activation=activation, padding=padding))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3),activation=activation, padding=padding))\n",
    "    model.add(Conv2D(256, (3, 3),activation=activation, padding=padding))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    # Flatten helps converting the data into 1-dimension array. for inputting full connected dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) # activation function\n",
    "    # The dropped while training this effect makes network less sensitive, also reduce the problem - less overfit\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    # compile the model with the parameters.\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "    return model\n",
    "# renaming the my_model as model\n",
    "model=my_model()\n",
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 64596 samples, validate on 7178 samples\n",
      "Epoch 1/1\n",
      "17344/64596 [=======>......................] - ETA: 33:37 - loss: 1.8199 - acc: 0.2858"
     ]
    }
   ],
   "source": [
    "#Define the K-fold Cross Validator\n",
    "num_folds = 3\n",
    "acc_per_fold = 0;\n",
    "loss_per_fold = 0;\n",
    "\n",
    "path_model = 'model_filter.h5'\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "\n",
    "  # Define the model architecture\n",
    "  model = my_model()\n",
    "    \n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "  # Fit data to model\n",
    "  history = model.fit(x=X_train, y=y_train,epochs=1,batch_size=64,verbose=1,validation_data=(X_test,y_test),shuffle=True, callbacks=[ModelCheckpoint(filepath=path_model, verbose=1, save_best_only=True),])\n",
    "\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "  acc_per_fold.append(scores[1] * 100)\n",
    "  loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxmEL5d4WmZY"
   },
   "outputs": [],
   "source": [
    "# for understanding the time consuming of the model, \n",
    "# starting the time\n",
    "start = timeit.default_timer()\n",
    "path_model='model_filter.h5' # saving model\n",
    "K.tensorflow_backend.clear_session() # destroys the current graph and builds a new one\n",
    "model=my_model() # create the model\n",
    "K.set_value(model.optimizer.lr,1e-3) # set the learning rate at 0.001\n",
    "# fit the model\n",
    "# parameter are x as x train data\n",
    "# y as y train data\n",
    "# batch size is 64, which means it take 64 samples from the dataset and train network. the defult value is 32, if its 64,128,256 are good for the model\n",
    "# epoches is 20\n",
    "# for validation data we are using X_test and Y_test.\n",
    "h=model.fit(x=X_train, y=y_train,epochs=20,batch_size=64,verbose=1,validation_data=(X_test,y_test),shuffle=True, callbacks=[ModelCheckpoint(filepath=path_model, verbose=1, save_best_only=True),])\n",
    "# time is stop at the end of all the epoches\n",
    "stop = timeit.default_timer()\n",
    "# printing the time \n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_4ab1l7WvO5"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QTHfYnIWrEL"
   },
   "outputs": [],
   "source": [
    "\n",
    "# evaluting the model with x_test and y_test.\n",
    "test_eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fxzG0-7W3D1"
   },
   "source": [
    "Graphical Representation of model accuracy and model loss for both training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxT9Q9ZCWzr4"
   },
   "outputs": [],
   "source": [
    "plt.plot(h.history['acc'])\n",
    "plt.plot(h.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(h.history['loss'])\n",
    "plt.plot(h.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
